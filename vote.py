import os
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
from collections import Counter
import pandas as pd
from tqdm import tqdm
import warnings
from transformers import CLIPModel, CLIPProcessor
from peft import LoraConfig, get_peft_model, TaskType
import glob

warnings.filterwarnings('ignore')

# --- é…ç½®å‚æ•° ---
# æ¨¡å‹è·¯å¾„é…ç½®
MODEL_PATHS = {
    'inception': "./lung_cancer_data/829_best_model.pth",
    'resnet': "./lung_cancer_data/resnet50_best_model.pth", 
    'clip_lora': "./lung_cancer_data/clip_lora_best_model.pth"
}

# CLIPæ¨¡å‹é…ç½®
LOCAL_CLIP_MODEL_PATH = "/Users/huangxh/Documents/DMECL/clip-vit-base-patch32-local"

# ç±»åˆ«å®šä¹‰ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
CLASSES = ['lung_aca', 'lung_n', 'lung_scc']  # è‚ºè…ºç™Œã€æ­£å¸¸ã€è‚ºé³ç™Œ
NUM_CLASSES = len(CLASSES)

# ç±»åˆ«ä¸­æ–‡åç§°æ˜ å°„
CLASS_NAMES_CN = {
    'lung_aca': 'è‚ºè…ºç™Œ',
    'lung_n': 'æ­£å¸¸',
    'lung_scc': 'è‚ºé³ç™Œ'
}

# LoRAé…ç½®ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
LORA_CONFIG = {
    "r": 32,
    "lora_alpha": 64,
    "lora_dropout": 0.05,
    "target_modules": [
        "q_proj", "k_proj", "v_proj", "out_proj",
        "fc1", "fc2"
    ]
}

# è®¾å¤‡æ£€æµ‹
def get_device():
    """è·å–æœ€ä½³å¯ç”¨è®¾å¤‡"""
    if torch.backends.mps.is_available():
        return torch.device("mps")
    elif torch.cuda.is_available():
        return torch.device("cuda")
    else:
        return torch.device("cpu")

DEVICE = get_device()
print(f"Using device: {DEVICE}")

# --- 1. Inceptionæ¨¡å‹å®šä¹‰ - ä¿®å¤ç‰ˆæœ¬ ---
def load_inception_model():
    """åŠ è½½Inception v3æ¨¡å‹ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬çš„torchvision"""
    try:
        model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
    except AttributeError:
        model = models.inception_v3(pretrained=True)
    return model

def create_inception_model(num_classes=NUM_CLASSES):
    """åˆ›å»ºä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„Inceptionæ¨¡å‹"""
    model = load_inception_model()
    
    # æ›¿æ¢åˆ†ç±»å™¨ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    
    # æ›¿æ¢è¾…åŠ©åˆ†ç±»å™¨ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    if hasattr(model, 'AuxLogits'):
        num_ftrs_aux = model.AuxLogits.fc.in_features
        model.AuxLogits.fc = nn.Linear(num_ftrs_aux, num_classes)
    
    return model

# --- 2. ResNet50æ¨¡å‹å®šä¹‰ ---
class ResNet50Classifier(nn.Module):
    """ResNet50 + è‡ªå®šä¹‰åˆ†ç±»å¤´æ¨¡å‹"""
    def __init__(self, num_classes=NUM_CLASSES, pretrained=False):
        super(ResNet50Classifier, self).__init__()
        
        self.backbone = models.resnet50(pretrained=pretrained)
        self.feature_dim = self.backbone.fc.in_features
        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(self.feature_dim, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        logits = self.classifier(features)
        return logits

# --- 3. CLIP+LoRAæ¨¡å‹å®šä¹‰ ---
class CLIPLoRAClassifier(nn.Module):
    """CLIP Vision Encoder + LoRA + å¢å¼ºåˆ†ç±»å¤´æ¨¡å‹"""
    def __init__(self, clip_model_name=LOCAL_CLIP_MODEL_PATH, num_classes=NUM_CLASSES, 
                 lora_config=LORA_CONFIG):
        super(CLIPLoRAClassifier, self).__init__()
        
        self.base_clip_model = CLIPModel.from_pretrained(clip_model_name)
        self.processor = CLIPProcessor.from_pretrained(clip_model_name)
        
        # å†»ç»“æ‰€æœ‰CLIPå‚æ•°
        for param in self.base_clip_model.parameters():
            param.requires_grad = False
        
        # é…ç½®LoRA
        self.lora_config = LoraConfig(
            r=lora_config["r"],
            lora_alpha=lora_config["lora_alpha"],
            target_modules=lora_config["target_modules"],
            lora_dropout=lora_config["lora_dropout"],
            bias="none",
            task_type=TaskType.FEATURE_EXTRACTION,
        )
        
        self.clip_model = get_peft_model(self.base_clip_model, self.lora_config)
        self.clip_hidden_size = self.base_clip_model.config.vision_config.hidden_size
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.1),
            nn.Linear(self.clip_hidden_size, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Dropout(0.2),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.1),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, pixel_values):
        vision_outputs = self.clip_model.vision_model(pixel_values=pixel_values)
        pooled_output = vision_outputs.pooler_output
        logits = self.classifier(pooled_output)
        return logits

# --- 4. æ™ºèƒ½æ¨¡å‹åŠ è½½å‡½æ•° ---
def smart_load_checkpoint(model, checkpoint_path, model_name):
    """æ™ºèƒ½åŠ è½½checkpointï¼Œè‡ªåŠ¨å¤„ç†ä¸åŒçš„ä¿å­˜æ ¼å¼"""
    try:
        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
        
        # æ£€æŸ¥checkpointçš„æ ¼å¼
        if isinstance(checkpoint, dict):
            if 'state_dict' in checkpoint:
                # æ ¼å¼: {"state_dict": model.state_dict()}
                print(f"Loading {model_name} with 'state_dict' format...")
                state_dict = checkpoint['state_dict']
            elif 'model_state_dict' in checkpoint:
                # æ ¼å¼: {"model_state_dict": model.state_dict()}
                print(f"Loading {model_name} with 'model_state_dict' format...")
                state_dict = checkpoint['model_state_dict']
            else:
                # ç›´æ¥æ˜¯state_dictæ ¼å¼
                print(f"Loading {model_name} with direct state_dict format...")
                state_dict = checkpoint
        else:
            # å¯èƒ½æ˜¯ç›´æ¥ä¿å­˜çš„æ¨¡å‹
            print(f"Loading {model_name} with direct model format...")
            state_dict = checkpoint
        
        # å°è¯•åŠ è½½state_dict
        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
        
        if len(missing_keys) > 0:
            print(f"âš ï¸  Missing keys in {model_name}: {missing_keys}")
        if len(unexpected_keys) > 0:
            print(f"âš ï¸  Unexpected keys in {model_name}: {unexpected_keys}")
        
        print(f"âœ… {model_name} model loaded successfully!")
        return True
        
    except Exception as e:
        print(f"âŒ Error loading {model_name} model: {e}")
        return False

# --- 5. å›¾åƒé¢„å¤„ç†å‡½æ•° ---
def get_transforms():
    """è·å–å„æ¨¡å‹çš„é¢„å¤„ç†å˜æ¢"""
    transforms_dict = {
        'inception': transforms.Compose([
            transforms.Resize(320),
            transforms.CenterCrop(299),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'resnet': transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ]),
        'clip_lora': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224)
        ])
    }
    return transforms_dict

# --- 6. å¤šæ¨¡å‹æŠ•ç¥¨åˆ†ç±»å™¨ ---
class EnsembleVotingClassifier:
    """å¤šæ¨¡å‹æŠ•ç¥¨åˆ†ç±»å™¨"""
    
    def __init__(self, model_paths=MODEL_PATHS):
        self.device = DEVICE
        self.models = {}
        self.transforms = get_transforms()
        
        # åªåœ¨éœ€è¦æ—¶åˆå§‹åŒ–CLIP processor
        self.clip_processor = None
        
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        self._load_models(model_paths)
    
    def _load_models(self, model_paths):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        print("Loading all models...")
        
        # åŠ è½½Inceptionæ¨¡å‹ - ä½¿ç”¨åŸç”Ÿæ¨¡å‹
        if os.path.exists(model_paths['inception']):
            print("Loading Inception model...")
            try:
                self.models['inception'] = create_inception_model()
                success = smart_load_checkpoint(
                    self.models['inception'], 
                    model_paths['inception'], 
                    'Inception'
                )
                if success:
                    self.models['inception'] = self.models['inception'].to(self.device)
                    self.models['inception'].eval()
                else:
                    del self.models['inception']
            except Exception as e:
                print(f"âŒ Failed to load Inception model: {e}")
        else:
            print(f"âŒ Inception model not found: {model_paths['inception']}")
        
        # åŠ è½½ResNet50æ¨¡å‹
        if os.path.exists(model_paths['resnet']):
            print("Loading ResNet50 model...")
            try:
                self.models['resnet'] = ResNet50Classifier()
                success = smart_load_checkpoint(
                    self.models['resnet'], 
                    model_paths['resnet'], 
                    'ResNet50'
                )
                if success:
                    self.models['resnet'] = self.models['resnet'].to(self.device)
                    self.models['resnet'].eval()
                else:
                    del self.models['resnet']
            except Exception as e:
                print(f"âŒ Failed to load ResNet50 model: {e}")
        else:
            print(f"âŒ ResNet50 model not found: {model_paths['resnet']}")
        
        # åŠ è½½CLIP+LoRAæ¨¡å‹
        if os.path.exists(model_paths['clip_lora']):
            print("Loading CLIP+LoRA model...")
            try:
                self.models['clip_lora'] = CLIPLoRAClassifier()
                success = smart_load_checkpoint(
                    self.models['clip_lora'], 
                    model_paths['clip_lora'], 
                    'CLIP+LoRA'
                )
                if success:
                    self.models['clip_lora'] = self.models['clip_lora'].to(self.device)
                    self.models['clip_lora'].eval()
                    # åˆå§‹åŒ–CLIP processor
                    self.clip_processor = CLIPProcessor.from_pretrained(LOCAL_CLIP_MODEL_PATH)
                else:
                    del self.models['clip_lora']
            except Exception as e:
                print(f"âŒ Failed to load CLIP+LoRA model: {e}")
        else:
            print(f"âŒ CLIP+LoRA model not found: {model_paths['clip_lora']}")
        
        print(f"Successfully loaded {len(self.models)} models: {list(self.models.keys())}")
        
        if len(self.models) == 0:
            raise RuntimeError("No models were successfully loaded! Please check your model paths and files.")
    
    def _preprocess_image(self, image_path, model_name):
        """ä¸ºç‰¹å®šæ¨¡å‹é¢„å¤„ç†å›¾åƒ"""
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            print(f"Error loading image {image_path}: {e}")
            return None
        
        if model_name == 'clip_lora' and self.clip_processor is not None:
            # CLIPæ¨¡å‹ä½¿ç”¨processor
            processed = self.clip_processor(images=image, return_tensors="pt")
            return processed['pixel_values'].to(self.device)
        else:
            # Inceptionå’ŒResNetä½¿ç”¨transforms
            transform = self.transforms[model_name]
            image_tensor = transform(image).unsqueeze(0)
            return image_tensor.to(self.device)
    
    def _predict_single_model(self, image_tensor, model_name):
        """ä½¿ç”¨å•ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if model_name not in self.models:
            return None, None, None
        
        model = self.models[model_name]
        
        with torch.no_grad():
            # ç‰¹æ®Šå¤„ç†Inceptionæ¨¡å‹çš„è®­ç»ƒæ¨¡å¼è¾“å‡º
            if model_name == 'inception' and hasattr(model, 'AuxLogits'):
                model.eval()  # ç¡®ä¿åœ¨è¯„ä¼°æ¨¡å¼
                outputs = model(image_tensor)
                # åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼ŒInceptionåªè¿”å›ä¸»è¾“å‡º
                if isinstance(outputs, tuple):
                    outputs = outputs[0]  # å–ä¸»è¾“å‡º
            else:
                outputs = model(image_tensor)
            
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs, 1)
            
            predicted_class_idx = predicted.item()
            predicted_class = CLASSES[predicted_class_idx]
            confidence = probabilities[0][predicted_class_idx].item()
            
            return predicted_class, confidence, probabilities[0].cpu().numpy()
    
    def predict_single_image(self, image_path, voting_method='majority', verbose=True):
        """å¯¹å•å¼ å›¾åƒè¿›è¡ŒæŠ•ç¥¨é¢„æµ‹"""
        if verbose:
            print(f"\n=== Predicting: {os.path.basename(image_path)} ===")
        
        predictions = {}
        all_probabilities = {}
        
        # è·å–æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹
        for model_name in self.models.keys():
            if verbose:
                print(f"Running {model_name} model...")
            
            # é¢„å¤„ç†å›¾åƒ
            image_tensor = self._preprocess_image(image_path, model_name)
            if image_tensor is None:
                continue
            
            # é¢„æµ‹
            pred_class, confidence, probs = self._predict_single_model(image_tensor, model_name)
            if pred_class is not None:
                predictions[model_name] = {
                    'class': pred_class,
                    'confidence': confidence,
                    'probabilities': probs
                }
                all_probabilities[model_name] = probs
                
                if verbose:
                    class_name_cn = CLASS_NAMES_CN.get(pred_class, pred_class)
                    print(f"  {model_name}: {class_name_cn} ({pred_class}) - {confidence:.4f}")
        
        # æŠ•ç¥¨å†³ç­–
        if not predictions:
            if verbose:
                print("âŒ No valid predictions from any model")
            return None, None, None
        
        final_prediction = self._vote(predictions, voting_method, verbose)
        
        return final_prediction, predictions, all_probabilities
    
    def _vote(self, predictions, method='majority', verbose=True):
        """æŠ•ç¥¨å†³ç­–"""
        if method == 'majority':
            # ç®€å•å¤šæ•°æŠ•ç¥¨
            votes = [pred['class'] for pred in predictions.values()]
            vote_counts = Counter(votes)
            final_class = vote_counts.most_common(1)[0][0]
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            class_confidences = [pred['confidence'] for pred in predictions.values() 
                               if pred['class'] == final_class]
            avg_confidence = np.mean(class_confidences)
            
            if verbose:
                print(f"\nğŸ—³ï¸  Voting Results:")
                print(f"Vote counts: {dict(vote_counts)}")
                print(f"Final prediction: {CLASS_NAMES_CN.get(final_class, final_class)} ({final_class})")
                print(f"Average confidence: {avg_confidence:.4f}")
            
            return {
                'final_class': final_class,
                'confidence': avg_confidence,
                'vote_counts': dict(vote_counts),
                'method': method
            }
        
        elif method == 'weighted':
            # åŸºäºç½®ä¿¡åº¦çš„åŠ æƒæŠ•ç¥¨
            weighted_probs = np.zeros(NUM_CLASSES)
            total_weight = 0
            
            for model_name, pred in predictions.items():
                weight = pred['confidence']
                weighted_probs += pred['probabilities'] * weight
                total_weight += weight
            
            if total_weight > 0:
                weighted_probs /= total_weight
            
            final_class_idx = np.argmax(weighted_probs)
            final_class = CLASSES[final_class_idx]
            final_confidence = weighted_probs[final_class_idx]
            
            if verbose:
                print(f"\nğŸ—³ï¸  Weighted Voting Results:")
                print(f"Final prediction: {CLASS_NAMES_CN.get(final_class, final_class)} ({final_class})")
                print(f"Weighted confidence: {final_confidence:.4f}")
            
            return {
                'final_class': final_class,
                'confidence': final_confidence,
                'weighted_probabilities': weighted_probs,
                'method': method
            }
    
    def predict_batch(self, image_paths, voting_method='majority', save_results=False):
        """æ‰¹é‡é¢„æµ‹ - ä¿®æ”¹ä¸ºä¸ä¿å­˜CSVï¼Œåªæ˜¾ç¤ºå‡†ç¡®ç‡ç»Ÿè®¡"""
        print(f"\n=== Batch Prediction: {len(image_paths)} images ===")
        
        results = []
        correct_predictions = 0
        total_predictions = 0
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        class_stats = {class_name: {'correct': 0, 'total': 0} for class_name in CLASSES}
        
        for i, image_path in enumerate(tqdm(image_paths, desc="Processing images")):
            try:
                final_pred, individual_preds, all_probs = self.predict_single_image(
                    image_path, voting_method, verbose=False  # æ‰¹é‡å¤„ç†æ—¶ä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                )
                
                if final_pred is not None:
                    # ä»æ–‡ä»¶è·¯å¾„æ¨æ–­çœŸå®æ ‡ç­¾ï¼ˆå¦‚æœå¯èƒ½ï¼‰
                    true_label = self._extract_true_label(image_path)
                    
                    if true_label:
                        class_stats[true_label]['total'] += 1
                        total_predictions += 1
                        
                        if final_pred['final_class'] == true_label:
                            class_stats[true_label]['correct'] += 1
                            correct_predictions += 1
                    
                    # ç®€åŒ–çš„ç»“æœè®°å½•ï¼ˆä¸ä¿å­˜è¯¦ç»†ä¿¡æ¯ï¼‰
                    result = {
                        'true_label': true_label,
                        'predicted_label': final_pred['final_class'],
                        'correct': final_pred['final_class'] == true_label if true_label else None
                    }
                    results.append(result)
                
            except Exception as e:
                print(f"Error processing {image_path}: {e}")
                continue
        
        # æ‰“å°è¯¦ç»†çš„å‡†ç¡®ç‡ç»Ÿè®¡
        self._print_accuracy_stats(class_stats, total_predictions, correct_predictions, voting_method)
        
        return results
    
    def _print_accuracy_stats(self, class_stats, total_predictions, correct_predictions, voting_method):
        """æ‰“å°è¯¦ç»†çš„å‡†ç¡®ç‡ç»Ÿè®¡"""
        print(f"\n" + "="*60)
        print(f"ğŸ“Š {voting_method.upper()} VOTING - ACCURACY RESULTS")
        print(f"="*60)
        
        # æ€»ä½“å‡†ç¡®ç‡
        if total_predictions > 0:
            overall_accuracy = correct_predictions / total_predictions
            print(f"ğŸ¯ Overall Accuracy: {overall_accuracy:.4f} ({correct_predictions}/{total_predictions})")
        else:
            print("ğŸ¯ Overall Accuracy: No valid predictions")
        
        print(f"\nğŸ“ˆ Accuracy by Class:")
        print("-" * 50)
        
        for class_name in CLASSES:
            stats = class_stats[class_name]
            if stats['total'] > 0:
                accuracy = stats['correct'] / stats['total']
                class_name_cn = CLASS_NAMES_CN.get(class_name, class_name)
                print(f"  {class_name_cn:8s} ({class_name:8s}): {accuracy:.4f} ({stats['correct']:3d}/{stats['total']:3d})")
            else:
                class_name_cn = CLASS_NAMES_CN.get(class_name, class_name)
                print(f"  {class_name_cn:8s} ({class_name:8s}): No samples")
        
        print("="*60)
    
    def _extract_true_label(self, image_path):
        """ä»æ–‡ä»¶è·¯å¾„æå–çœŸå®æ ‡ç­¾"""
        for class_name in CLASSES:
            if class_name in image_path:
                return class_name
        return None

# --- 7. ä¿®æ”¹åçš„ä¸»å‡½æ•° ---
def main():
    """ä¸»å‡½æ•° - ä¿®æ”¹ä¸ºå¤„ç†æ‰€æœ‰LC25000æ•°æ®"""
    try:
        # åˆ›å»ºæŠ•ç¥¨åˆ†ç±»å™¨
        ensemble = EnsembleVotingClassifier()
        
        # æ”¶é›†æ‰€æœ‰æµ‹è¯•å›¾ç‰‡
        test_images = []
        dataset_path = "/Users/huangxh/Documents/DMECL/LC25000"
        
        if os.path.exists(dataset_path):
            print(f"ğŸ“ Loading all images from {dataset_path}")
            
            for class_name in CLASSES:
                class_dir = os.path.join(dataset_path, class_name)
                if os.path.exists(class_dir):
                    # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾ç‰‡
                    class_images = []
                    for ext in ['*.jpeg', '*.jpg', '*.png']:
                        class_images.extend(glob.glob(os.path.join(class_dir, ext)))
                    
                    test_images.extend(class_images)
                    class_name_cn = CLASS_NAMES_CN.get(class_name, class_name)
                    print(f"  {class_name_cn} ({class_name}): {len(class_images)} images")
            
            print(f"\nğŸ” Total images to process: {len(test_images)}")
            
            if test_images:
                # ç®€å•å¤šæ•°æŠ•ç¥¨
                print(f"\n{'='*60}")
                print(f"ğŸ—³ï¸  Running MAJORITY VOTING on all {len(test_images)} images")
                print(f"{'='*60}")
                
                results_majority = ensemble.predict_batch(
                    test_images, voting_method='majority', save_results=False
                )
                
                # åŠ æƒæŠ•ç¥¨
                print(f"\n{'='*60}")
                print(f"ğŸ—³ï¸  Running WEIGHTED VOTING on all {len(test_images)} images")
                print(f"{'='*60}")
                
                results_weighted = ensemble.predict_batch(
                    test_images, voting_method='weighted', save_results=False
                )
                
                # æ¯”è¾ƒä¸¤ç§æŠ•ç¥¨æ–¹æ³•
                print(f"\n{'='*60}")
                print(f"ğŸ“Š VOTING METHODS COMPARISON")
                print(f"{'='*60}")
                print(f"Total images processed: {len(test_images)}")
                print(f"Majority voting and weighted voting results shown above.")
                
            else:
                print("âŒ No images found in the dataset!")
        else:
            print(f"âŒ Dataset path not found: {dataset_path}")
            
    except Exception as e:
        print(f"âŒ Error in main function: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()