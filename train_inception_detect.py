import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import time
import copy
import multiprocessing
import warnings
import glob
warnings.filterwarnings('ignore')

# --- 1. é…ç½®å‚æ•° ---
# è·¯å¾„è®¾ç½®
BASE_DIR = "./lung_cancer_data"
MODEL_SAVE_PATH = os.path.join(BASE_DIR, "829_best_model.pth")

# æœ¬åœ°æ•°æ®é›†è·¯å¾„
LOCAL_DATASET_PATH = "/Users/huangxh/Documents/DMECL/LC25000"

# è®­ç»ƒå‚æ•°
BATCH_SIZE = 16
NUM_EPOCHS = 10
LEARNING_RATE = 0.001

# è®¾å¤‡æ£€æµ‹ - æ”¯æŒApple Silicon
def get_device():
    """
    è·å–æœ€ä½³å¯ç”¨è®¾å¤‡ï¼Œä¼˜å…ˆçº§ï¼šMPS > CUDA > CPU
    """
    if torch.backends.mps.is_available():
        return torch.device("mps")
    elif torch.cuda.is_available():
        return torch.device("cuda")
    else:
        return torch.device("cpu")

DEVICE = get_device()

# LC25000æ•°æ®é›†çš„ç±»åˆ«
CLASSES = ['lung_aca', 'lung_n', 'lung_scc']  # è‚ºè…ºç™Œã€æ­£å¸¸ã€è‚ºé³ç™Œ
NUM_CLASSES = len(CLASSES)

print(f"Using device: {DEVICE}")
if DEVICE.type == "mps":
    print("âœ… Apple Silicon GPU (MPS) acceleration enabled!")
    print("ğŸ’¡ Tip: You can try increasing BATCH_SIZE for better performance")
elif DEVICE.type == "cuda":
    print("âœ… NVIDIA GPU (CUDA) acceleration enabled!")
else:
    print("âš ï¸  Using CPU - consider upgrading PyTorch for MPS support")

print(f"Available CPU cores: {multiprocessing.cpu_count()}")



# --- 2. ä¿®æ”¹åçš„å›¾åƒéªŒè¯å‡½æ•° ---
def is_valid_image(image_path):
    """
    æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ - ä¿®å¤ç‰ˆæœ¬
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if os.path.getsize(image_path) <= 200:  # Git LFSæŒ‡é’ˆæ–‡ä»¶é€šå¸¸å¾ˆå°
            return False
        
        # å°è¯•æ‰“å¼€å¹¶è¯»å–å›¾åƒ
        with Image.open(image_path) as img:
            # è·å–å›¾åƒæ ¼å¼å’Œå°ºå¯¸
            img.load()  # ç¡®ä¿å›¾åƒæ•°æ®è¢«åŠ è½½
            _ = img.size  # è·å–å°ºå¯¸
            _ = img.mode  # è·å–æ¨¡å¼
        return True
    except Exception as e:
        print(f"Invalid image {image_path}: {e}")
        return False

def load_and_verify_image(image_path):
    """
    å®‰å…¨åœ°åŠ è½½å›¾åƒï¼Œå¤„ç†æŸåçš„æ–‡ä»¶ - ä¿®å¤ç‰ˆæœ¬
    """
    try:
        image = Image.open(image_path).convert('RGB')
        # å°è¯•è·å–å›¾åƒå°ºå¯¸æ¥ç¡®ä¿å›¾åƒå®Œæ•´
        _ = image.size
        # å°è¯•åŠ è½½å›¾åƒæ•°æ®
        image.load()
        return image
    except Exception as e:
        print(f"Warning: Cannot load image {image_path}: {e}")
        return None

# --- 3. ä¿®æ”¹åçš„æœ¬åœ°æ•°æ®é›†ç±» ---
class LocalImageDataset(Dataset):
    """
    æœ¬åœ°å›¾åƒæ•°æ®é›†ç±»ï¼Œå¸¦æœ‰æ”¹è¿›çš„é”™è¯¯å¤„ç†
    """
    def __init__(self, image_paths, labels, transform=None, class_to_idx=None):
        self.original_image_paths = image_paths.copy()
        self.original_labels = labels.copy()
        self.transform = transform
        self.class_to_idx = class_to_idx or {}
        
        # éªŒè¯å¹¶è¿‡æ»¤æœ‰æ•ˆçš„å›¾åƒ - ä½¿ç”¨æ›´å®½æ¾çš„éªŒè¯
        self._validate_images()
        
    def _validate_images(self):
        """éªŒè¯å›¾åƒæ–‡ä»¶å¹¶ç§»é™¤æŸåçš„æ–‡ä»¶ - æ”¹è¿›ç‰ˆæœ¬"""
        print("Validating image files...")
        valid_indices = []
        invalid_count = 0
        
        # ä½¿ç”¨æ›´å®½æ¾çš„éªŒè¯ç­–ç•¥
        for idx, image_path in enumerate(tqdm(self.original_image_paths, desc="Validating images")):
            try:
                # åŸºæœ¬æ£€æŸ¥ï¼šæ–‡ä»¶å­˜åœ¨ä¸”ä¸ä¸ºç©º
                if not os.path.exists(image_path):
                    invalid_count += 1
                    print(f"File not found: {image_path}")
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦æ˜¯Git LFSæŒ‡é’ˆæ–‡ä»¶
                file_size = os.path.getsize(image_path)
                if file_size <= 200:  # Git LFSæŒ‡é’ˆæ–‡ä»¶é€šå¸¸å¾ˆå°
                    invalid_count += 1
                    print(f"Git LFS pointer file (not downloaded): {image_path}")
                    continue
                
                # å°è¯•å¿«é€Ÿæ‰“å¼€å›¾åƒï¼ˆä¸ä½¿ç”¨verifyï¼‰
                try:
                    with Image.open(image_path) as img:
                        # åªæ£€æŸ¥åŸºæœ¬å±æ€§
                        _ = img.size
                        _ = img.mode
                    valid_indices.append(idx)
                except Exception as img_error:
                    # å¦‚æœPILæ— æ³•æ‰“å¼€ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                    try:
                        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                        ext = os.path.splitext(image_path)[1].lower()
                        if ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:
                            # å¯¹äºå¸¸è§æ ¼å¼ï¼Œç»™ä¸€æ¬¡æœºä¼š
                            valid_indices.append(idx)
                        else:
                            invalid_count += 1
                            print(f"Unsupported format: {image_path}")
                    except:
                        invalid_count += 1
                        print(f"Cannot process: {image_path}")
                        
            except Exception as e:
                invalid_count += 1
                print(f"Error validating {image_path}: {e}")
        
        # æ›´æ–°æœ‰æ•ˆçš„å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
        self.image_paths = [self.original_image_paths[i] for i in valid_indices]
        self.labels = [self.original_labels[i] for i in valid_indices]
        
        print(f"Validation complete: {len(self.image_paths)} valid images, {invalid_count} invalid images removed")
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå›¾åƒï¼Œç»™å‡ºè¯¦ç»†ä¿¡æ¯
        if len(self.image_paths) == 0:
            print("WARNING: No valid images found!")
            print("This is likely because Git LFS files haven't been downloaded.")
            print("Please run: cd /Users/huangxh/Documents/DMECL/LC25000 && git lfs pull")
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        image_path = self.image_paths[idx]
        
        # å°è¯•å¤šç§æ–¹å¼åŠ è½½å›¾åƒ
        image = None
        try:
            image = Image.open(image_path).convert('RGB')
            # ç¡®ä¿å›¾åƒå¯ä»¥è¢«å¤„ç†
            _ = image.size
        except Exception as e:
            print(f"Warning: Cannot load image {image_path}: {e}")
            # åˆ›å»ºä¸€ä¸ªé»˜è®¤å›¾åƒ
            image = Image.new('RGB', (224, 224), color=(128, 128, 128))  # ç°è‰²é»˜è®¤å›¾åƒ
        
        # è·å–æ ‡ç­¾
        label = self.labels[idx]
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            try:
                image = self.transform(image)
            except Exception as e:
                print(f"Transform failed for {image_path}: {e}")
                # å¦‚æœå˜æ¢å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„tensor
                image = torch.zeros(3, 299, 299)
        
        # å¤„ç†æ ‡ç­¾
        if isinstance(label, str) and self.class_to_idx:
            label = self.class_to_idx.get(label, 0)
        
        return image, label

# --- 4. æ•°æ®åŠ è½½å‡½æ•° ---
def load_local_dataset():
    """
    ä»æœ¬åœ°ç›®å½•åŠ è½½LC25000æ•°æ®é›†ï¼Œå¸¦æœ‰æ–‡ä»¶éªŒè¯
    """
    print("--- Loading local LC25000 dataset ---")
    
    if not os.path.exists(LOCAL_DATASET_PATH):
        raise FileNotFoundError(f"Dataset directory not found: {LOCAL_DATASET_PATH}")
    
    image_paths = []
    labels = []
    class_to_idx = {}
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
    
    # æ–¹æ³•1: å¦‚æœæ•°æ®æŒ‰ç±»åˆ«åˆ†åœ¨ä¸åŒæ–‡ä»¶å¤¹ä¸­
    class_dirs = [d for d in os.listdir(LOCAL_DATASET_PATH) 
                  if os.path.isdir(os.path.join(LOCAL_DATASET_PATH, d)) and not d.startswith('.')]
    
    if class_dirs:
        print("Found class directories:", class_dirs)
        
        # åˆ›å»ºç±»åˆ«æ˜ å°„
        class_to_idx = {cls: idx for idx, cls in enumerate(sorted(class_dirs))}
        idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}
        
        # åŠ è½½æ¯ä¸ªç±»åˆ«çš„å›¾åƒ
        for class_name in class_dirs:
            class_dir = os.path.join(LOCAL_DATASET_PATH, class_name)
            
            # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶
            class_images = []
            for ext in image_extensions:
                class_images.extend(glob.glob(os.path.join(class_dir, ext)))
            
            print(f"Found {len(class_images)} potential images in class '{class_name}'")
            
            # éªŒè¯å›¾åƒæ–‡ä»¶
            valid_images = []
            for img_path in class_images:
                if os.path.getsize(img_path) > 200:  # è¿‡æ»¤Git LFSæŒ‡é’ˆæ–‡ä»¶
                    valid_images.append(img_path)
                else:
                    print(f"Skipping Git LFS pointer file: {img_path}")
            
            print(f"Valid images in class '{class_name}': {len(valid_images)}")
            
            # æ·»åŠ åˆ°æ€»åˆ—è¡¨
            image_paths.extend(valid_images)
            labels.extend([class_name] * len(valid_images))
    
    print(f"Total images loaded: {len(image_paths)}")
    print(f"Classes: {list(class_to_idx.keys())}")
    print(f"Class distribution:")
    for cls in class_to_idx.keys():
        count = labels.count(cls)
        print(f"  {cls}: {count} images")
    
    return image_paths, labels, class_to_idx, idx_to_class

def create_data_splits_local(image_paths, labels, class_to_idx):
    """
    å°†æœ¬åœ°æ•°æ®é›†åˆ†å‰²ä¸ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†
    """
    print("--- Creating data splits ---")
    
    # è·å–æ‰€æœ‰ç´¢å¼•
    indices = list(range(len(image_paths)))
    
    # åˆ†å±‚é‡‡æ ·
    try:
        # å°†æ ‡ç­¾è½¬æ¢ä¸ºæ•°å­—
        numeric_labels = [class_to_idx[label] if isinstance(label, str) else label 
                         for label in labels]
        
        # 70% è®­ç»ƒ, 30% ä¸´æ—¶
        train_indices, temp_indices = train_test_split(
            indices, test_size=0.3, random_state=42, stratify=numeric_labels
        )
        
        # ä»ä¸´æ—¶æ•°æ®ä¸­åˆ†å‡ºéªŒè¯å’Œæµ‹è¯• (15% + 15%)
        temp_labels = [numeric_labels[i] for i in temp_indices]
        val_indices, test_indices = train_test_split(
            temp_indices, test_size=0.5, random_state=42, stratify=temp_labels
        )
        
    except Exception as e:
        print(f"Stratified split failed: {e}, using random split")
        # éšæœºåˆ†å‰²
        train_indices, temp_indices = train_test_split(
            indices, test_size=0.3, random_state=42
        )
        val_indices, test_indices = train_test_split(
            temp_indices, test_size=0.5, random_state=42
        )
    
    print(f"Train samples: {len(train_indices)}")
    print(f"Validation samples: {len(val_indices)}")
    print(f"Test samples: {len(test_indices)}")
    
    # åˆ›å»ºåˆ†å‰²åçš„æ•°æ®
    splits = {}
    for split_name, indices in [('train', train_indices), 
                               ('validation', val_indices), 
                               ('test', test_indices)]:
        splits[split_name] = {
            'image_paths': [image_paths[i] for i in indices],
            'labels': [labels[i] for i in indices]
        }
    
    return splits

# def create_data_loaders_local():
#     """
#     åˆ›å»ºæœ¬åœ°æ•°æ®é›†çš„æ•°æ®åŠ è½½å™¨
#     """
#     print("--- Creating data loaders ---")
    
#     # åŠ è½½æœ¬åœ°æ•°æ®é›†
#     image_paths, labels, class_to_idx, idx_to_class = load_local_dataset()
    
#     if len(image_paths) == 0:
#         print("No valid images found. Please download Git LFS files first.")
#         return None, None, None, None, None
    
#     # åˆ†å‰²æ•°æ®
#     data_splits = create_data_splits_local(image_paths, labels, class_to_idx)
    
#     # æ•°æ®é¢„å¤„ç†å’Œå¢å¼º
#     data_transforms = {
#         'train': transforms.Compose([
#             transforms.Resize((320, 320)),  # å…ˆresizeåˆ°ç¨å¤§çš„å°ºå¯¸
#             transforms.RandomResizedCrop(299),  # Inception v3éœ€è¦299x299
#             transforms.RandomHorizontalFlip(),
#             transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
#             transforms.RandomRotation(10),
#             transforms.ToTensor(),
#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
#         ]),
#         'validation': transforms.Compose([
#             transforms.Resize(320),
#             transforms.CenterCrop(299),
#             transforms.ToTensor(),
#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
#         ]),
#     }
    
#     # åˆ›å»ºPyTorch Dataset
#     pytorch_datasets = {}
#     for split in ['train', 'validation', 'test']:
#         pytorch_datasets[split] = LocalImageDataset(
#             data_splits[split]['image_paths'],
#             data_splits[split]['labels'],
#             data_transforms.get(split, data_transforms['validation']),
#             class_to_idx
#         )
    
#     # ä¿®æ”¹num_workersè®¾ç½®ï¼Œå‡å°‘å¹¶å‘ä»¥é¿å…é—®é¢˜
#     num_workers = 0  # è®¾ç½®ä¸º0ä»¥é¿å…å¤šè¿›ç¨‹é—®é¢˜
    
#     # åˆ›å»ºæ•°æ®åŠ è½½å™¨
#     dataloaders = {}
#     for split in ['train', 'validation']:
#         dataloaders[split] = DataLoader(
#             pytorch_datasets[split],
#             batch_size=BATCH_SIZE,
#             shuffle=(split == 'train'),
#             num_workers=num_workers,  # ä½¿ç”¨å•è¿›ç¨‹
#             pin_memory=torch.cuda.is_available(),
#             drop_last=True
#         )
    
#     dataset_sizes = {split: len(pytorch_datasets[split]) for split in ['train', 'validation']}
    
#     return pytorch_datasets, dataloaders, dataset_sizes, class_to_idx, idx_to_class

def create_data_loaders_local():
    """
    åˆ›å»ºæœ¬åœ°æ•°æ®é›†çš„æ•°æ®åŠ è½½å™¨
    """
    print("--- Creating data loaders ---")
    
    # åŠ è½½æœ¬åœ°æ•°æ®é›†
    image_paths, labels, class_to_idx, idx_to_class = load_local_dataset()
    
    if len(image_paths) == 0:
        print("No valid images found. Please download Git LFS files first.")
        return None, None, None, None, None, None  # å¢åŠ ä¸€ä¸ªè¿”å›å€¼
    
    # åˆ†å‰²æ•°æ®
    data_splits = create_data_splits_local(image_paths, labels, class_to_idx)
    
    # æ•°æ®é¢„å¤„ç†å’Œå¢å¼º
    data_transforms = {
        'train': transforms.Compose([
            transforms.Resize((320, 320)),
            transforms.RandomResizedCrop(299),
            transforms.RandomHorizontalFlip(),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'validation': transforms.Compose([
            transforms.Resize(320),
            transforms.CenterCrop(299),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'test': transforms.Compose([  # æ·»åŠ testçš„å˜æ¢
            transforms.Resize(320),
            transforms.CenterCrop(299),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    }
    
    # åˆ›å»ºPyTorch Dataset
    pytorch_datasets = {}
    for split in ['train', 'validation', 'test']:
        pytorch_datasets[split] = LocalImageDataset(
            data_splits[split]['image_paths'],
            data_splits[split]['labels'],
            data_transforms.get(split, data_transforms['validation']),
            class_to_idx
        )
    
    # ä¿®æ”¹num_workersè®¾ç½®ï¼Œå‡å°‘å¹¶å‘ä»¥é¿å…é—®é¢˜
    num_workers = 0
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - åŒ…æ‹¬test
    dataloaders = {}
    for split in ['train', 'validation', 'test']:  # æ·»åŠ test
        dataloaders[split] = DataLoader(
            pytorch_datasets[split],
            batch_size=BATCH_SIZE,
            shuffle=(split == 'train'),
            num_workers=num_workers,
            pin_memory=torch.cuda.is_available(),
            drop_last=False  # testæ—¶ä¸è¦drop_last
        )
    
    dataset_sizes = {split: len(pytorch_datasets[split]) for split in ['train', 'validation', 'test']}
    
    return pytorch_datasets, dataloaders, dataset_sizes, class_to_idx, idx_to_class, data_splits  # è¿”å›data_splitsç”¨äºè°ƒè¯•
# --- 5. æ¨¡å‹ç›¸å…³å‡½æ•° ---
def load_inception_model():
    """åŠ è½½Inception v3æ¨¡å‹ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬çš„torchvision"""
    try:
        model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
        print("Loaded model with new torchvision API")
    except AttributeError:
        model = models.inception_v3(pretrained=True)
        print("Loaded model with legacy torchvision API")
    return model

def test_model(model, test_dataloader, dataset_size, class_to_idx, idx_to_class):
    """
    æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹
    """
    print("\n--- Testing model on test dataset ---")
    
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    running_corrects = 0
    all_preds = []
    all_labels = []
    
    # ç”¨äºè®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
    class_correct = {i: 0 for i in range(len(class_to_idx))}
    class_total = {i: 0 for i in range(len(class_to_idx))}
    
    with torch.no_grad():
        pbar = tqdm(test_dataloader, desc="Testing")
        
        for inputs, labels in pbar:
            inputs = inputs.to(DEVICE)
            labels = labels.to(DEVICE)
            
            # å‰å‘ä¼ æ’­
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            
            # ç»Ÿè®¡æ­£ç¡®é¢„æµ‹
            running_corrects += torch.sum(preds == labels.data)
            
            # ä¿å­˜é¢„æµ‹ç»“æœç”¨äºè¯¦ç»†åˆ†æ
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
            for i in range(labels.size(0)):
                label = labels[i].item()
                pred = preds[i].item()
                class_total[label] += 1
                if label == pred:
                    class_correct[label] += 1
    
    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    test_acc = running_corrects.item() / dataset_size
    
    print(f"\n=== Test Results ===")
    print(f"Overall Test Accuracy: {test_acc:.4f} ({running_corrects}/{dataset_size})")
    
    # æ‰“å°æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
    print(f"\nPer-class Accuracy:")
    for class_idx, class_name in idx_to_class.items():
        if class_total[class_idx] > 0:
            class_acc = class_correct[class_idx] / class_total[class_idx]
            print(f"  {class_name}: {class_acc:.4f} ({class_correct[class_idx]}/{class_total[class_idx]})")
        else:
            print(f"  {class_name}: No samples in test set")
    
    return test_acc, all_preds, all_labels
# --- 6. è®­ç»ƒå‡½æ•° ---
def train_model():
    """
    ä½¿ç”¨Inception v3æ¨¡å‹è®­ç»ƒæœ¬åœ°LC25000æ•°æ®é›†
    """
    print("\n--- Training on local LC25000 dataset ---")
    print(f"Using device: {DEVICE}")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    result = create_data_loaders_local()
    if result[0] is None:
        print("Error: Failed to create data loaders")
        return None
    
    pytorch_datasets, dataloaders, dataset_sizes, class_to_idx, idx_to_class,data_splits = result
    
    if dataset_sizes['train'] == 0:
        print("Error: No training data found.")
        return None

    print(f"Dataset sizes: {dataset_sizes}")
    print(f"Classes: {list(class_to_idx.keys())}")

    # åŠ è½½é¢„è®­ç»ƒçš„Inception v3æ¨¡å‹
    model = load_inception_model()
    
    # æ›¿æ¢åˆ†ç±»å™¨ï¼ˆæ ¹æ®å®é™…ç±»åˆ«æ•°ï¼‰
    num_ftrs = model.fc.in_features
    actual_num_classes = len(class_to_idx)
    model.fc = nn.Linear(num_ftrs, actual_num_classes)
    
    # æ›¿æ¢è¾…åŠ©åˆ†ç±»å™¨
    if hasattr(model, 'AuxLogits'):
        num_ftrs_aux = model.AuxLogits.fc.in_features
        model.AuxLogits.fc = nn.Linear(num_ftrs_aux, actual_num_classes)

    model = model.to(DEVICE)

    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

    # è®­ç»ƒå¾ªç¯
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    patience = 5
    patience_counter = 0

    print("Starting training...")
    start_time = time.time()

    for epoch in range(NUM_EPOCHS):
        print(f'Epoch {epoch+1}/{NUM_EPOCHS}')
        print('-' * 10)

        for phase in ['train', 'validation']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            pbar = tqdm(dataloaders[phase], desc=f"Epoch {epoch+1} - {phase}")
            
            for inputs, labels in pbar:
                inputs = inputs.to(DEVICE)
                labels = labels.to(DEVICE)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    try:
                        if phase == 'train' and hasattr(model, 'AuxLogits'):
                            outputs, aux_outputs = model(inputs)
                            loss1 = criterion(outputs, labels)
                            loss2 = criterion(aux_outputs, labels)
                            loss = loss1 + 0.4 * loss2
                        else:
                            outputs = model(inputs)
                            loss = criterion(outputs, labels)

                        _, preds = torch.max(outputs, 1)

                        if phase == 'train':
                            loss.backward()
                            optimizer.step()

                    except RuntimeError as e:
                        print(f"Runtime error during {phase}: {e}")
                        continue

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.item() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            if phase == 'validation':
                if epoch_acc > best_acc:
                    best_acc = epoch_acc
                    best_model_wts = copy.deepcopy(model.state_dict())
                    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)
                    torch.save(model.state_dict(), MODEL_SAVE_PATH)
                    print(f"New best model saved with accuracy: {best_acc:.4f}")
                    patience_counter = 0
                else:
                    patience_counter += 1

        if phase == 'train':
            scheduler.step()

        if patience_counter >= patience:
            print(f"Early stopping triggered after {epoch+1} epochs")
            break

    total_time = time.time() - start_time
    print(f'Training completed in {total_time:.0f}s')
    print(f'Best validation accuracy: {best_acc:.4f}')

    model.load_state_dict(best_model_wts)
    return model, class_to_idx, idx_to_class, dataloaders

# --- 7. æ·»åŠ æ•°æ®é›†è¯Šæ–­å‡½æ•° ---
def diagnose_dataset(dataset_path):
    """
    è¯Šæ–­æ•°æ®é›†é—®é¢˜
    """
    print(f"\n=== Dataset Diagnosis for {dataset_path} ===")
    
    if not os.path.exists(dataset_path):
        print(f"âŒ Dataset directory does not exist: {dataset_path}")
        return False
    
    # æ£€æŸ¥ç›®å½•ç»“æ„
    items = os.listdir(dataset_path)
    print(f"Items in dataset directory: {items}")
    
    # æ£€æŸ¥ç±»åˆ«ç›®å½•
    class_dirs = [d for d in items if os.path.isdir(os.path.join(dataset_path, d)) and not d.startswith('.')]
    print(f"Class directories found: {class_dirs}")
    
    if not class_dirs:
        print("âŒ No class directories found")
        return False
    
    # æ£€æŸ¥æ¯ä¸ªç±»åˆ«çš„æ–‡ä»¶
    total_files = 0
    git_lfs_files = 0
    for class_dir in class_dirs:
        class_path = os.path.join(dataset_path, class_dir)
        files = os.listdir(class_path)
        print(f"\nClass '{class_dir}':")
        print(f"  Total files: {len(files)}")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        image_files = []
        for f in files:
            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
                image_files.append(f)
        
        print(f"  Image files: {len(image_files)}")
        
        # æ£€æŸ¥å‰å‡ ä¸ªæ–‡ä»¶
        for i, img_file in enumerate(image_files[:3]):
            img_path = os.path.join(class_path, img_file)
            size = os.path.getsize(img_path)
            print(f"    Sample {i+1}: {img_file} ({size} bytes)")
            
            if size <= 200:
                git_lfs_files += 1
                print(f"      âš ï¸  Git LFS pointer file (not downloaded)")
            else:
                # å°è¯•æ‰“å¼€å›¾åƒ
                try:
                    with Image.open(img_path) as img:
                        print(f"      âœ… Format: {img.format}, Size: {img.size}, Mode: {img.mode}")
                        total_files += 1
                except Exception as e:
                    print(f"      âŒ Cannot open: {e}")
    
    print(f"\nSummary:")
    print(f"  Valid image files: {total_files}")
    print(f"  Git LFS pointer files: {git_lfs_files}")
    
    if git_lfs_files > 0:
        print(f"\nâš ï¸  Found {git_lfs_files} Git LFS pointer files.")
        print("Please run the following commands to download the actual files:")
        print(f"  cd {dataset_path}")
        print("  git lfs pull")
    
    return total_files > 0

# --- 8. ä¿®æ”¹ä¸»å‡½æ•° ---
def main():
    """ä¸»å‡½æ•°"""
    try:
        print("=== Local LC25000 Lung Cancer Classification ===")
        print(f"PyTorch version: {torch.__version__}")
        print(f"Device: {DEVICE}")
        print(f"Local dataset path: {LOCAL_DATASET_PATH}")
        print()

        # æ£€æŸ¥æœ¬åœ°æ•°æ®é›†è·¯å¾„
        if not os.path.exists(LOCAL_DATASET_PATH):
            print(f"âœ— Dataset directory not found: {LOCAL_DATASET_PATH}")
            print("Please make sure the LC25000 dataset is in the correct location.")
            return
        else:
            print(f"âœ“ Dataset directory found: {LOCAL_DATASET_PATH}")

        # è¯Šæ–­æ•°æ®é›†
        if not diagnose_dataset(LOCAL_DATASET_PATH):
            print("âŒ Dataset diagnosis failed. Please check your dataset structure.")
            return

        # è®­ç»ƒæ¨¡å‹
        result = train_model()
        
        if result is not None:
            model, class_to_idx, idx_to_class,dataloaders = result
            print("Training completed successfully!")
            print(f"Model saved at: {MODEL_SAVE_PATH}")
            print(f"Class mapping: {class_to_idx}")

            # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
            if 'test' in dataloaders:
                # é‡æ–°åˆ›å»ºæ•°æ®åŠ è½½å™¨ä»¥è·å–dataset_sizes
                _, _, dataset_sizes, _, _, _ = create_data_loaders_local()
                
                test_acc, test_preds, test_labels = test_model(
                    model, 
                    dataloaders['test'], 
                    dataset_sizes['test'], 
                    class_to_idx, 
                    idx_to_class
                )
                
                print(f"\nğŸ‰ Final Test Accuracy: {test_acc:.4f}")
            else:
                print("âŒ Test dataloader not available")
        else:
            print("Training failed!")
            return
        
        print("\n=== Training completed! ===")
        
    except KeyboardInterrupt:
        print("\nTraining interrupted by user")
    except Exception as e:
        print(f"Error in main pipeline: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()