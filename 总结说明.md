本仓库一共实现了三种分类器
1.inception_v3为主体的分类器，对模型没有修改，全部模型都开放训练
2.CLIP+Lora+分类头的分类器，整体思路是在CLIP的encoder部分加入Lora，并对lora+分类头进行微调，同时对损失函数进行修改(具体看appendix A)
3.resnet50+Lora+分类头的分类器,全部参数都开放训练
（train是对应的训练代码，demo是对应的推理代码，允许用户给定图片进行分类）


其次，实现了一种投票的机制，使用三种模型分别对一个样本进行投票，有两种方式的投票，一种是正常投票，一种是加权投票
最后想要结合三种模型的性能，这里详见Appendix B
这里也提供了推理代码，即vote_demo.py

📋 使用方法
单次预测：

bash
python vote_demo.py --image "/Users/huangxh/Documents/DMECL/LC25000/lung_aca/lungaca1.jpeg" --method majority

交互式使用：

bash
python vote_demo.py --interactive

批量测试：

bash
python vote_demo.py --image image1.jpg --method majority
python vote_demo.py --image image2.jpg --method weighted



此外，由于没有明确的将数据集进行区分，这里在对全部数据集实现了模型检测，single_test是对单个模型的检测
vote.py是对多个模型进行正确率检测
前者的结果相见：single_result.png
后者的结果详见: vote_result.png

整体来说，对于单个模型，CLIP+Lora+分类头的分类器效果最好
对于投票机制，采用加权的方式最好，略优于单模型，简单投票方式会处于单模型效果中间，有点中和的意思






Appendix A: 损失函数

这里第二种方式，由于不是CNN卷积结构，对图像的识别效果不是特别好，所以对损失函数进行修正
1. 三种损失函数的定义
标准交叉熵损失 (CrossEntropyLoss)
Python
criterion_ce = nn.CrossEntropyLoss()
作用：基础的分类损失，确保模型学习基本的分类能力
特点：对所有样本一视同仁，是最基础的监督信号
标签平滑交叉熵损失 (Label Smoothing)
Python
class LabelSmoothingCrossEntropy(nn.Module):
    def __init__(self, smoothing=0.1):
        super(LabelSmoothingCrossEntropy, self).__init__()
        self.smoothing = smoothing
        
    def forward(self, pred, target):
        confidence = 1. - self.smoothing  # 0.9
        logprobs = F.log_softmax(pred, dim=-1)
        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))
        nll_loss = nll_loss.squeeze(1)
        smooth_loss = -logprobs.mean(dim=-1)
        loss = confidence * nll_loss + self.smoothing * smooth_loss
        return loss.mean()
优化原理：

防止过拟合：不让模型对预测过于自信
提高泛化能力：真实标签权重0.9，其他类别平均分配0.1
缓解标签噪声：对于医学图像中可能存在的标注不确定性很有效
Focal Loss
Python
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)  # 预测概率
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()
优化原理：

关注难样本：(1-pt)^gamma 项让模型更关注预测错误的样本
降低易样本权重：预测正确的样本权重会被大幅降低
解决样本难度不均：特别适合肺腺癌和肺鳞癌这种相似度高的类别
2. 组合损失函数
Python
def combined_loss(outputs, labels):
    loss_ce = criterion_ce(outputs, labels)
    loss_ls = criterion_ls(outputs, labels)
    loss_focal = criterion_focal(outputs, labels)
    return 0.4 * loss_ce + 0.3 * loss_ls + 0.3 * loss_focal
权重分配策略：

40% 标准交叉熵：保证基础分类能力
30% 标签平滑：提高泛化能力，防止过拟合
30% Focal Loss：专注难样本，提高对相似类别的区分能力
3. 优化效果分析
针对你的问题（正常类别准确但肺腺癌/肺鳞癌混淆）：
Focal Loss的作用：

肺腺癌和肺鳞癌相似度高，容易被误分类
Focal Loss会给这些"难样本"更高的权重
强迫模型学习更细致的特征区别
Label Smoothing的作用：

防止模型对"正常"类别过于自信
提高模型在边界样本上的泛化能力
减少过拟合风险
组合效应：

三种损失互补，既保证基础性能，又针对性解决难点
权重可以根据实际效果调整



Appendix B: 投票机制

1. 简单多数投票 (Majority Voting)
原理：每个模型投一票，最终结果由得票最多的类别决定。

实现逻辑：

Python
# 简单多数投票
votes = [pred['class'] for pred in predictions.values()]
vote_counts = Counter(votes)
final_class = vote_counts.most_common(1)[0][0]

# 计算平均置信度
class_confidences = [pred['confidence'] for pred in predictions.values() 
                   if pred['class'] == final_class]
avg_confidence = np.mean(class_confidences)
特点：

每个模型的权重相等，都是1票
不考虑模型的置信度差异
最终置信度是投票给获胜类别的所有模型置信度的平均值
适合模型性能相近的情况
示例：

Inception预测：肺腺癌 (0.85)
ResNet50预测：肺腺癌 (0.72)
CLIP+LoRA预测：正常 (0.68)
结果：肺腺癌获得2票，正常获得1票 → 最终预测：肺腺癌，置信度：(0.85+0.72)/2 = 0.785
2. 加权投票 (Weighted Voting)
原理：根据每个模型的预测置信度进行加权，置信度高的模型影响力更大。

实现逻辑：

Python
# 基于置信度的加权投票
weighted_probs = np.zeros(NUM_CLASSES)
total_weight = 0

for model_name, pred in predictions.items():
    weight = pred['confidence']  # 使用置信度作为权重
    weighted_probs += pred['probabilities'] * weight
    total_weight += weight

if total_weight > 0:
    weighted_probs /= total_weight

final_class_idx = np.argmax(weighted_probs)
final_class = CLASSES[final_class_idx]
final_confidence = weighted_probs[final_class_idx]
特点：

每个模型的权重等于其预测置信度
考虑了模型对预测的确信程度
最终结果是所有类别概率的加权平均
适合模型性能差异较大的情况
示例：
假设三个类别的概率分布：

Inception：[0.85, 0.10, 0.05]，置信度0.85
ResNet50：[0.72, 0.20, 0.08]，置信度0.72
CLIP+LoRA：[0.30, 0.68, 0.02]，置信度0.68
加权计算：

weighted_probs = (0.85*[0.85,0.10,0.05] + 0.72*[0.72,0.20,0.08] + 0.68*[0.30,0.68,0.02]) / (0.85+0.72+0.68)
两种方法的对比
特征	简单多数投票	加权投票
权重分配	每个模型权重相等	根据置信度分配权重
适用场景	模型性能相近	模型性能差异较大
计算复杂度	简单	稍复杂
对异常值敏感性	较低	较高
最终置信度	获胜类别模型的平均置信度	加权概率的最大值
使用建议
简单多数投票：当你的三个模型（Inception、ResNet50、CLIP+LoRA）性能相近时使用
加权投票：当某个模型明显优于其他模型，或者你希望让高置信度的预测有更大影响力时使用