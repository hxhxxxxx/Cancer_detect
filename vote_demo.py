import os
import sys
import argparse
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
from collections import Counter
import warnings
from transformers import CLIPModel, CLIPProcessor
from peft import LoraConfig, get_peft_model, TaskType
import time

warnings.filterwarnings('ignore')

# --- é…ç½®å‚æ•° ---
# æ¨¡å‹è·¯å¾„é…ç½®
MODEL_PATHS = {
    'inception': "./lung_cancer_data/829_best_model.pth",
    'resnet': "./lung_cancer_data/resnet50_best_model.pth", 
    'clip_lora': "./lung_cancer_data/clip_lora_best_model.pth"
}

# CLIPæ¨¡å‹é…ç½®
LOCAL_CLIP_MODEL_PATH = "/Users/huangxh/Documents/DMECL/clip-vit-base-patch32-local"

# ç±»åˆ«å®šä¹‰ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
CLASSES = ['lung_aca', 'lung_n', 'lung_scc']  # è‚ºè…ºç™Œã€æ­£å¸¸ã€è‚ºé³ç™Œ
NUM_CLASSES = len(CLASSES)

# ç±»åˆ«ä¸­æ–‡åç§°æ˜ å°„
CLASS_NAMES_CN = {
    'lung_aca': 'è‚ºè…ºç™Œ',
    'lung_n': 'æ­£å¸¸',
    'lung_scc': 'è‚ºé³ç™Œ'
}

# ç±»åˆ«è¯¦ç»†æè¿°
CLASS_DESCRIPTIONS = {
    'lung_aca': {
        'name_cn': 'è‚ºè…ºç™Œ',
        'name_en': 'Lung Adenocarcinoma',
        'description': 'è‚ºè…ºç™Œæ˜¯è‚ºç™Œçš„ä¸€ç§ç±»å‹ï¼Œé€šå¸¸å‘ç”Ÿåœ¨è‚ºçš„å¤–å‘¨éƒ¨ä½'
    },
    'lung_n': {
        'name_cn': 'æ­£å¸¸',
        'name_en': 'Normal',
        'description': 'æ­£å¸¸çš„è‚ºéƒ¨ç»„ç»‡ï¼Œæ— ç—…ç†æ”¹å˜'
    },
    'lung_scc': {
        'name_cn': 'è‚ºé³ç™Œ',
        'name_en': 'Lung Squamous Cell Carcinoma',
        'description': 'è‚ºé³çŠ¶ç»†èƒç™Œï¼Œé€šå¸¸å‘ç”Ÿåœ¨è‚ºçš„ä¸­å¤®éƒ¨ä½'
    }
}

# LoRAé…ç½®ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
LORA_CONFIG = {
    "r": 32,
    "lora_alpha": 64,
    "lora_dropout": 0.05,
    "target_modules": [
        "q_proj", "k_proj", "v_proj", "out_proj",
        "fc1", "fc2"
    ]
}

# è®¾å¤‡æ£€æµ‹
def get_device():
    """è·å–æœ€ä½³å¯ç”¨è®¾å¤‡"""
    if torch.backends.mps.is_available():
        return torch.device("mps")
    elif torch.cuda.is_available():
        return torch.device("cuda")
    else:
        return torch.device("cpu")

DEVICE = get_device()

# --- æ¨¡å‹å®šä¹‰ï¼ˆä»vote_fix.pyå¤åˆ¶ï¼‰ ---
def load_inception_model():
    """åŠ è½½Inception v3æ¨¡å‹ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬çš„torchvision"""
    try:
        model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)
    except AttributeError:
        model = models.inception_v3(pretrained=True)
    return model

def create_inception_model(num_classes=NUM_CLASSES):
    """åˆ›å»ºä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„Inceptionæ¨¡å‹"""
    model = load_inception_model()
    
    # æ›¿æ¢åˆ†ç±»å™¨ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    
    # æ›¿æ¢è¾…åŠ©åˆ†ç±»å™¨ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    if hasattr(model, 'AuxLogits'):
        num_ftrs_aux = model.AuxLogits.fc.in_features
        model.AuxLogits.fc = nn.Linear(num_ftrs_aux, num_classes)
    
    return model

class ResNet50Classifier(nn.Module):
    """ResNet50 + è‡ªå®šä¹‰åˆ†ç±»å¤´æ¨¡å‹"""
    def __init__(self, num_classes=NUM_CLASSES, pretrained=False):
        super(ResNet50Classifier, self).__init__()
        
        self.backbone = models.resnet50(pretrained=pretrained)
        self.feature_dim = self.backbone.fc.in_features
        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(self.feature_dim, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        logits = self.classifier(features)
        return logits

class CLIPLoRAClassifier(nn.Module):
    """CLIP Vision Encoder + LoRA + å¢å¼ºåˆ†ç±»å¤´æ¨¡å‹"""
    def __init__(self, clip_model_name=LOCAL_CLIP_MODEL_PATH, num_classes=NUM_CLASSES, 
                 lora_config=LORA_CONFIG):
        super(CLIPLoRAClassifier, self).__init__()
        
        self.base_clip_model = CLIPModel.from_pretrained(clip_model_name)
        self.processor = CLIPProcessor.from_pretrained(clip_model_name)
        
        # å†»ç»“æ‰€æœ‰CLIPå‚æ•°
        for param in self.base_clip_model.parameters():
            param.requires_grad = False
        
        # é…ç½®LoRA
        self.lora_config = LoraConfig(
            r=lora_config["r"],
            lora_alpha=lora_config["lora_alpha"],
            target_modules=lora_config["target_modules"],
            lora_dropout=lora_config["lora_dropout"],
            bias="none",
            task_type=TaskType.FEATURE_EXTRACTION,
        )
        
        self.clip_model = get_peft_model(self.base_clip_model, self.lora_config)
        self.clip_hidden_size = self.base_clip_model.config.vision_config.hidden_size
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.1),
            nn.Linear(self.clip_hidden_size, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Dropout(0.2),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.1),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, pixel_values):
        vision_outputs = self.clip_model.vision_model(pixel_values=pixel_values)
        pooled_output = vision_outputs.pooler_output
        logits = self.classifier(pooled_output)
        return logits

def smart_load_checkpoint(model, checkpoint_path, model_name):
    """æ™ºèƒ½åŠ è½½checkpointï¼Œè‡ªåŠ¨å¤„ç†ä¸åŒçš„ä¿å­˜æ ¼å¼"""
    try:
        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
        
        # æ£€æŸ¥checkpointçš„æ ¼å¼
        if isinstance(checkpoint, dict):
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        # å°è¯•åŠ è½½state_dict
        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
        
        if len(missing_keys) > 0:
            print(f"âš ï¸  Missing keys in {model_name}: {len(missing_keys)} keys")
        if len(unexpected_keys) > 0:
            print(f"âš ï¸  Unexpected keys in {model_name}: {len(unexpected_keys)} keys")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error loading {model_name} model: {e}")
        return False

def get_transforms():
    """è·å–å„æ¨¡å‹çš„é¢„å¤„ç†å˜æ¢"""
    transforms_dict = {
        'inception': transforms.Compose([
            transforms.Resize(320),
            transforms.CenterCrop(299),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'resnet': transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ]),
        'clip_lora': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224)
        ])
    }
    return transforms_dict

# --- æŠ•ç¥¨åˆ†ç±»å™¨ç±» ---
class LungCancerEnsembleClassifier:
    """è‚ºç™Œå¤šæ¨¡å‹æŠ•ç¥¨åˆ†ç±»å™¨"""
    
    def __init__(self, model_paths=MODEL_PATHS, verbose=True):
        self.device = DEVICE
        self.models = {}
        self.transforms = get_transforms()
        self.clip_processor = None
        self.verbose = verbose
        
        if self.verbose:
            print(f"ğŸ”§ Initializing Lung Cancer Ensemble Classifier")
            print(f"ğŸ“± Using device: {self.device}")
        
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        self._load_models(model_paths)
    
    def _load_models(self, model_paths):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        if self.verbose:
            print("\nğŸ“¦ Loading models...")
        
        loaded_count = 0
        
        # åŠ è½½Inceptionæ¨¡å‹
        if os.path.exists(model_paths['inception']):
            if self.verbose:
                print("  ğŸ”„ Loading Inception v3 model...")
            try:
                self.models['inception'] = create_inception_model()
                success = smart_load_checkpoint(
                    self.models['inception'], 
                    model_paths['inception'], 
                    'Inception'
                )
                if success:
                    self.models['inception'] = self.models['inception'].to(self.device)
                    self.models['inception'].eval()
                    loaded_count += 1
                    if self.verbose:
                        print("    âœ… Inception v3 loaded successfully")
                else:
                    del self.models['inception']
            except Exception as e:
                if self.verbose:
                    print(f"    âŒ Failed to load Inception model: {e}")
        else:
            if self.verbose:
                print(f"    âš ï¸  Inception model not found: {model_paths['inception']}")
        
        # åŠ è½½ResNet50æ¨¡å‹
        if os.path.exists(model_paths['resnet']):
            if self.verbose:
                print("  ğŸ”„ Loading ResNet50 model...")
            try:
                self.models['resnet'] = ResNet50Classifier()
                success = smart_load_checkpoint(
                    self.models['resnet'], 
                    model_paths['resnet'], 
                    'ResNet50'
                )
                if success:
                    self.models['resnet'] = self.models['resnet'].to(self.device)
                    self.models['resnet'].eval()
                    loaded_count += 1
                    if self.verbose:
                        print("    âœ… ResNet50 loaded successfully")
                else:
                    del self.models['resnet']
            except Exception as e:
                if self.verbose:
                    print(f"    âŒ Failed to load ResNet50 model: {e}")
        else:
            if self.verbose:
                print(f"    âš ï¸  ResNet50 model not found: {model_paths['resnet']}")
        
        # åŠ è½½CLIP+LoRAæ¨¡å‹
        if os.path.exists(model_paths['clip_lora']):
            if self.verbose:
                print("  ğŸ”„ Loading CLIP+LoRA model...")
            try:
                self.models['clip_lora'] = CLIPLoRAClassifier()
                success = smart_load_checkpoint(
                    self.models['clip_lora'], 
                    model_paths['clip_lora'], 
                    'CLIP+LoRA'
                )
                if success:
                    self.models['clip_lora'] = self.models['clip_lora'].to(self.device)
                    self.models['clip_lora'].eval()
                    self.clip_processor = CLIPProcessor.from_pretrained(LOCAL_CLIP_MODEL_PATH)
                    loaded_count += 1
                    if self.verbose:
                        print("    âœ… CLIP+LoRA loaded successfully")
                else:
                    del self.models['clip_lora']
            except Exception as e:
                if self.verbose:
                    print(f"    âŒ Failed to load CLIP+LoRA model: {e}")
        else:
            if self.verbose:
                print(f"    âš ï¸  CLIP+LoRA model not found: {model_paths['clip_lora']}")
        
        if self.verbose:
            print(f"\nğŸ“Š Successfully loaded {loaded_count}/3 models: {list(self.models.keys())}")
        
        if len(self.models) == 0:
            raise RuntimeError("âŒ No models were successfully loaded! Please check your model paths and files.")
    
    def _preprocess_image(self, image_path, model_name):
        """ä¸ºç‰¹å®šæ¨¡å‹é¢„å¤„ç†å›¾åƒ"""
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            raise ValueError(f"Error loading image {image_path}: {e}")
        
        if model_name == 'clip_lora' and self.clip_processor is not None:
            # CLIPæ¨¡å‹ä½¿ç”¨processor
            processed = self.clip_processor(images=image, return_tensors="pt")
            return processed['pixel_values'].to(self.device)
        else:
            # Inceptionå’ŒResNetä½¿ç”¨transforms
            transform = self.transforms[model_name]
            image_tensor = transform(image).unsqueeze(0)
            return image_tensor.to(self.device)
    
    def _predict_single_model(self, image_tensor, model_name):
        """ä½¿ç”¨å•ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if model_name not in self.models:
            return None, None, None
        
        model = self.models[model_name]
        
        with torch.no_grad():
            # ç‰¹æ®Šå¤„ç†Inceptionæ¨¡å‹çš„è®­ç»ƒæ¨¡å¼è¾“å‡º
            if model_name == 'inception' and hasattr(model, 'AuxLogits'):
                model.eval()  # ç¡®ä¿åœ¨è¯„ä¼°æ¨¡å¼
                outputs = model(image_tensor)
                # åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼ŒInceptionåªè¿”å›ä¸»è¾“å‡º
                if isinstance(outputs, tuple):
                    outputs = outputs[0]  # å–ä¸»è¾“å‡º
            else:
                outputs = model(image_tensor)
            
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs, 1)
            
            predicted_class_idx = predicted.item()
            predicted_class = CLASSES[predicted_class_idx]
            confidence = probabilities[0][predicted_class_idx].item()
            
            return predicted_class, confidence, probabilities[0].cpu().numpy()
    
    def predict(self, image_path, voting_method='majority'):
        """å¯¹å•å¼ å›¾åƒè¿›è¡ŒæŠ•ç¥¨é¢„æµ‹"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
        
        if self.verbose:
            print(f"\nğŸ” Analyzing image: {os.path.basename(image_path)}")
        
        predictions = {}
        all_probabilities = {}
        
        # è·å–æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹
        for model_name in self.models.keys():
            if self.verbose:
                print(f"  ğŸ¤– Running {model_name} model...")
            
            # é¢„å¤„ç†å›¾åƒ
            image_tensor = self._preprocess_image(image_path, model_name)
            
            # é¢„æµ‹
            pred_class, confidence, probs = self._predict_single_model(image_tensor, model_name)
            if pred_class is not None:
                predictions[model_name] = {
                    'class': pred_class,
                    'confidence': confidence,
                    'probabilities': probs
                }
                all_probabilities[model_name] = probs
                
                if self.verbose:
                    class_name_cn = CLASS_NAMES_CN.get(pred_class, pred_class)
                    print(f"    ğŸ“Š {model_name}: {class_name_cn} ({confidence:.3f})")
        
        # æŠ•ç¥¨å†³ç­–
        if not predictions:
            raise RuntimeError("âŒ No valid predictions from any model")
        
        final_prediction = self._vote(predictions, voting_method)
        
        return final_prediction, predictions, all_probabilities
    
    def _vote(self, predictions, method='majority'):
        """æŠ•ç¥¨å†³ç­–"""
        if method == 'majority':
            # ç®€å•å¤šæ•°æŠ•ç¥¨
            votes = [pred['class'] for pred in predictions.values()]
            vote_counts = Counter(votes)
            final_class = vote_counts.most_common(1)[0][0]
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            class_confidences = [pred['confidence'] for pred in predictions.values() 
                               if pred['class'] == final_class]
            avg_confidence = np.mean(class_confidences)
            
            return {
                'final_class': final_class,
                'confidence': avg_confidence,
                'vote_counts': dict(vote_counts),
                'method': method
            }
        
        elif method == 'weighted':
            # åŸºäºç½®ä¿¡åº¦çš„åŠ æƒæŠ•ç¥¨
            weighted_probs = np.zeros(NUM_CLASSES)
            total_weight = 0
            
            for model_name, pred in predictions.items():
                weight = pred['confidence']
                weighted_probs += pred['probabilities'] * weight
                total_weight += weight
            
            if total_weight > 0:
                weighted_probs /= total_weight
            
            final_class_idx = np.argmax(weighted_probs)
            final_class = CLASSES[final_class_idx]
            final_confidence = weighted_probs[final_class_idx]
            
            return {
                'final_class': final_class,
                'confidence': final_confidence,
                'weighted_probabilities': weighted_probs,
                'method': method
            }

# --- ç»“æœæ˜¾ç¤ºå‡½æ•° ---
def print_prediction_results(final_prediction, individual_predictions, image_path):
    """æ‰“å°è¯¦ç»†çš„é¢„æµ‹ç»“æœ"""
    print("\n" + "="*70)
    print("ğŸ« è‚ºç™Œæ™ºèƒ½è¯Šæ–­ç³»ç»Ÿ - é¢„æµ‹ç»“æœ / Lung Cancer AI Diagnosis - Results")
    print("="*70)
    
    # å›¾åƒä¿¡æ¯
    print(f"ğŸ“ å›¾åƒæ–‡ä»¶: {os.path.basename(image_path)}")
    print(f"ğŸ“ å®Œæ•´è·¯å¾„: {image_path}")
    
    # ä¸ªä½“æ¨¡å‹é¢„æµ‹ç»“æœ
    print(f"\nğŸ¤– å„æ¨¡å‹é¢„æµ‹ç»“æœ:")
    print("-" * 50)
    for model_name, pred in individual_predictions.items():
        class_info = CLASS_DESCRIPTIONS[pred['class']]
        print(f"  {model_name:12s}: {class_info['name_cn']:6s} ({pred['class']:8s}) - ç½®ä¿¡åº¦: {pred['confidence']:.3f}")
    
    # æŠ•ç¥¨ç»“æœ
    print(f"\nğŸ—³ï¸  é›†æˆæŠ•ç¥¨ç»“æœ:")
    print("-" * 50)
    final_class = final_prediction['final_class']
    final_confidence = final_prediction['confidence']
    class_info = CLASS_DESCRIPTIONS[final_class]
    
    print(f"ğŸ¯ æœ€ç»ˆé¢„æµ‹: {class_info['name_cn']} ({class_info['name_en']})")
    print(f"ğŸ“Š ç»¼åˆç½®ä¿¡åº¦: {final_confidence:.3f}")
    print(f"ğŸ”¬ æŠ•ç¥¨æ–¹æ³•: {final_prediction['method']}")
    
    if 'vote_counts' in final_prediction:
        print(f"ğŸ“ˆ æŠ•ç¥¨ç»Ÿè®¡: {final_prediction['vote_counts']}")
    
    # ç±»åˆ«æè¿°
    print(f"\nğŸ“ è¯Šæ–­è¯´æ˜:")
    print(f"   {class_info['description']}")
    
    # ç½®ä¿¡åº¦è§£é‡Š
    confidence_level = "é«˜" if final_confidence > 0.8 else "ä¸­" if final_confidence > 0.6 else "ä½"
    print(f"\nâš¡ ç½®ä¿¡åº¦è¯„ä¼°: {confidence_level}ç½®ä¿¡åº¦")
    
    if final_confidence > 0.8:
        print("   âœ… æ¨¡å‹å¯¹æ­¤é¢„æµ‹éå¸¸ç¡®ä¿¡")
    elif final_confidence > 0.6:
        print("   âš ï¸  æ¨¡å‹å¯¹æ­¤é¢„æµ‹è¾ƒä¸ºç¡®ä¿¡ï¼Œå»ºè®®ç»“åˆå…¶ä»–æ£€æŸ¥")
    else:
        print("   âš ï¸  æ¨¡å‹å¯¹æ­¤é¢„æµ‹ä¸å¤Ÿç¡®ä¿¡ï¼Œå¼ºçƒˆå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥")
    
    print("="*70)
    print("âš ï¸  å…è´£å£°æ˜: æ­¤ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»å­¦è¯Šæ–­")
    print("="*70)

def print_welcome():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    print("="*70)
    print("ğŸ« è‚ºç™Œæ™ºèƒ½è¯Šæ–­ç³»ç»Ÿ / Lung Cancer AI Diagnosis System")
    print("="*70)
    print("ğŸ“‹ æ”¯æŒçš„å›¾åƒæ ¼å¼: .jpg, .jpeg, .png, .bmp, .tiff")
    print("ğŸ¤– é›†æˆæ¨¡å‹: Inception v3 + ResNet50 + CLIP+LoRA")
    print("ğŸ—³ï¸  æŠ•ç¥¨æ–¹æ³•: majority (å¤šæ•°æŠ•ç¥¨) / weighted (åŠ æƒæŠ•ç¥¨)")
    print("="*70)

# --- ä¸»è¦åŠŸèƒ½å‡½æ•° ---
def predict_single_image(image_path, voting_method='majority', verbose=True):
    """é¢„æµ‹å•å¼ å›¾åƒ"""
    try:
        # åˆå§‹åŒ–åˆ†ç±»å™¨
        classifier = LungCancerEnsembleClassifier(verbose=verbose)
        
        # è¿›è¡Œé¢„æµ‹
        start_time = time.time()
        final_pred, individual_preds, all_probs = classifier.predict(image_path, voting_method)
        end_time = time.time()
        
        # æ˜¾ç¤ºç»“æœ
        if verbose:
            print_prediction_results(final_pred, individual_preds, image_path)
            print(f"\nâ±ï¸  é¢„æµ‹è€—æ—¶: {end_time - start_time:.2f} ç§’")
        
        return final_pred, individual_preds
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return None, None

def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print_welcome()
    
    classifier = None
    
    while True:
        print(f"\n{'='*50}")
        print("ğŸ® äº¤äº’æ¨¡å¼ - è¯·é€‰æ‹©æ“ä½œ:")
        print("1. é¢„æµ‹å›¾åƒ (å¤šæ•°æŠ•ç¥¨)")
        print("2. é¢„æµ‹å›¾åƒ (åŠ æƒæŠ•ç¥¨)")
        print("3. é€€å‡º")
        print("="*50)
        
        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-3): ").strip()
        
        if choice == '3':
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨è‚ºç™Œæ™ºèƒ½è¯Šæ–­ç³»ç»Ÿ!")
            break
        elif choice in ['1', '2']:
            image_path = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip().strip('"\'')
            
            if not os.path.exists(image_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                continue
            
            voting_method = 'majority' if choice == '1' else 'weighted'
            
            try:
                # å»¶è¿Ÿåˆå§‹åŒ–åˆ†ç±»å™¨
                if classifier is None:
                    print("\nğŸ”§ é¦–æ¬¡ä½¿ç”¨ï¼Œæ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
                    classifier = LungCancerEnsembleClassifier(verbose=True)
                
                # è¿›è¡Œé¢„æµ‹
                start_time = time.time()
                final_pred, individual_preds, _ = classifier.predict(image_path, voting_method)
                end_time = time.time()
                
                # æ˜¾ç¤ºç»“æœ
                print_prediction_results(final_pred, individual_preds, image_path)
                print(f"\nâ±ï¸  é¢„æµ‹è€—æ—¶: {end_time - start_time:.2f} ç§’")
                
            except Exception as e:
                print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        else:
            print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")

# --- å‘½ä»¤è¡Œæ¥å£ ---
def main():
    parser = argparse.ArgumentParser(
        description="è‚ºç™Œæ™ºèƒ½è¯Šæ–­ç³»ç»Ÿ - Lung Cancer AI Diagnosis System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python demo.py --image /path/to/image.jpg                    # ä½¿ç”¨å¤šæ•°æŠ•ç¥¨
  python demo.py --image /path/to/image.jpg --method weighted  # ä½¿ç”¨åŠ æƒæŠ•ç¥¨
  python demo.py --interactive                                 # äº¤äº’æ¨¡å¼
        """
    )
    
    parser.add_argument('--image', '-i', type=str, help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--method', '-m', choices=['majority', 'weighted'], 
                       default='majority', help='æŠ•ç¥¨æ–¹æ³• (é»˜è®¤: majority)')
    parser.add_argument('--interactive', action='store_true', help='å¯åŠ¨äº¤äº’æ¨¡å¼')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œå‡å°‘è¾“å‡º')
    
    args = parser.parse_args()
    
    if args.interactive:
        interactive_mode()
    elif args.image:
        if not os.path.exists(args.image):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {args.image}")
            sys.exit(1)
        
        if not args.quiet:
            print_welcome()
        
        predict_single_image(args.image, args.method, verbose=not args.quiet)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()